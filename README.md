# DFD
![Bilkent logo](Bilkent.svg)
Digitally manipulated face images/videos, and especially those obtained via the recent artificial intelligence and deep learning algorithms which are commonly referred to as “DeepFake” (DF) techniques, present highly realistic looking images/videos of people saying and doing fake things. Such fake content now possesses the capacity to pose a significant impact on how one may decide the validity of information spread online. Such content modification and generation techniques may affect the human rights and the quality of public discourse-especially considering that DeepFakes may be deployed maliciously as a mechanism for manipulation, misinformation, persuasion and harassment. Due to the rapid advancement of DeepFake techniques, identification and detection of digitally manipulated media has become a technically demanding and rapidly evolving major challenge.
The majority of the existing DeepFake detection methods in the literature assume the problem as a closed-set two-class recognition task and collect both real and fake data to train a binary classifier to detect fake content. This modelling formalism, however, suffers from certain drawbacks. First, creation of fake training data is both computationally demanding and time consuming. Second, and more important, in the test phase, the trained binary classifiers are biased towards detecting samples which are generated by the models “seen” during the training stage. Any test sample which may be potentially developed using an “unseen model” then has a high chance of passing the detection system. Since, the creation of new DeepFake models has a fast pace as one may witness from the relevant literature, the DF detection problem in real-world settings is quite a challenging one.
Considering that DeepFakes pose a great threat to both the individuals as well as the society as a whole, the current project aims to propose and implement new and high-performance automated techniques for the DeepFake detection problem, and to improve upon the state-of-the-art methods in the real-world and challenging conditions of DeepFake image/videos. In this context, a particular focus shall be placed on the “unseen” scenario where a test sample is generated using a DeepFake model that was not seen during the training stage of the system. 
